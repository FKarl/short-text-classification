{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Short Texts Of Products and Services (STOPS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define paths\n",
    "PATH_TO_YELP = 'source/yelp/yelp_academic_dataset_business.json'\n",
    "PATH_TO_MAVE_POS = 'source/mave/mave_positives.jsonl'\n",
    "PATH_TO_MAVE_NEG = 'source/mave/mave_negatives.jsonl'\n",
    "\n",
    "PATH_TO_BINARY_RESULTS = 'STOPS-2-long/STOPS-2'\n",
    "PATH_TO_RESULTS = 'STOPS-long/STOPS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# define parameters\n",
    "RANDOM_STATE = 42\n",
    "TRAIN_SPLIT = 0.7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def read_jsonline(file_path):\n",
    "    # read file line by line\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as f:\n",
    "        while True:\n",
    "            jsonline = f.readline()\n",
    "            if not jsonline:\n",
    "                break\n",
    "            yield json.loads(jsonline)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def countWords(sentence):\n",
    "    words = sentence.split()\n",
    "    return len(words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import string\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    # remove multiple spaces\n",
    "    text = ' '.join(text.split())\n",
    "    # remove punctuation\n",
    "    text = text.translate(text.maketrans('', '', string.punctuation))\n",
    "    # map to unicode\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mave"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def count_mave(path, label_counter, limit_words, limits_cat, min_char_count):\n",
    "    for line in read_jsonline(path):\n",
    "        if not line:\n",
    "            break\n",
    "        if (len(line['paragraphs']) >= 1) and (line['paragraphs'][0]['source'] == 'title') and (line['category']):\n",
    "            text = line['paragraphs'][0]['text']\n",
    "            if (countWords(text) <= limit_words) and (len(text) >= min_char_count):\n",
    "                label = line['category']\n",
    "                if label not in label_counter:\n",
    "                    label_counter[label] = 0\n",
    "                if label_counter[label] < limits_cat:\n",
    "                    label_counter[label] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def load_mave(path, texts, label_counter, top_cats, limit_words, limits_cat, min_char_count):\n",
    "    for line in read_jsonline(path):\n",
    "        if not line:\n",
    "            break\n",
    "        if (len(line['paragraphs']) >= 1) and (line['paragraphs'][0]['source'] == 'title') and (line['category']):\n",
    "            text = line['paragraphs'][0]['text']\n",
    "            label = line['category']\n",
    "            if label not in label_counter:\n",
    "                label_counter[label] = 0\n",
    "            if (label in top_cats) and (label_counter[label] < limits_cat):\n",
    "                texts.append((label, preprocess(text)))\n",
    "                label_counter[label] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "size = 5000\n",
    "min_char_count = 5\n",
    "limit_words = 7\n",
    "mave_texts = []\n",
    "label_counter = dict()\n",
    "\n",
    "# count most frequent labels\n",
    "count_mave(PATH_TO_MAVE_POS, label_counter, limit_words, size, min_char_count)\n",
    "count_mave(PATH_TO_MAVE_NEG, label_counter, limit_words, size, min_char_count)\n",
    "\n",
    "top_cats = sorted(label_counter.items(), key=lambda x: x[1], reverse=True)\n",
    "# select 20 most frequent labels\n",
    "top_cats = top_cats[:20]\n",
    "top_cats = [cat for cat, count in top_cats]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# load most frequent labels\n",
    "label_counter = dict()\n",
    "\n",
    "load_mave(PATH_TO_MAVE_POS, mave_texts, label_counter, top_cats, limit_words, size, min_char_count)\n",
    "load_mave(PATH_TO_MAVE_NEG, mave_texts, label_counter, top_cats, limit_words, size, min_char_count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Yelp Business Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# count label occurences\n",
    "count_labels = dict()\n",
    "for line in read_jsonline(PATH_TO_YELP):\n",
    "    if not line:\n",
    "        break\n",
    "\n",
    "    if line['categories'] and line['name']:\n",
    "        label = line['categories']\n",
    "\n",
    "        categories = label.replace(\", \", \",\").split(\",\")\n",
    "        for category in categories:\n",
    "            if category not in count_labels:\n",
    "                count_labels[category] = 0\n",
    "            count_labels[category] += 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# order by occurrences\n",
    "count_labels = sorted(count_labels.items(), key=lambda x: x[1], reverse=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# map data points to the most frequent label\n",
    "yelp_texts = []\n",
    "limit = 12000\n",
    "label_counter = dict()\n",
    "\n",
    "for line in read_jsonline(PATH_TO_YELP):\n",
    "    if not line:\n",
    "        break\n",
    "\n",
    "    if line['categories'] and line['name']:\n",
    "        categories = line['categories'].replace(\", \", \",\").split(\",\")\n",
    "        # find first label in label list\n",
    "        for label, _ in count_labels:\n",
    "            if label in categories:\n",
    "                if label not in label_counter:\n",
    "                    label_counter[label] = 0\n",
    "                label_counter[label] += 1\n",
    "\n",
    "                if label_counter[label] <= limit:\n",
    "                    text = str(line['name'])\n",
    "                    yelp_texts.append((label, preprocess(text)))\n",
    "\n",
    "                break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YELP length: 100341\n",
      "MAVE length: 100000\n",
      "YELP labels: {'Pets', 'Financial Services', 'Local Services', 'Public Services & Government', 'Restaurants', 'Food', 'Nightlife', 'Hotels & Travel', 'Education', 'Event Planning & Services', 'Beauty & Spas', 'Active Life', 'Mass Media', 'Automotive', 'Religious Organizations', 'Health & Medical', 'Professional Services', 'Arts & Entertainment', 'Local Flavor', 'Home Services', 'Shopping'}\n",
      "MAVE labels: {'Sunglasses', 'Socks', 'Stuffed Animals', 'Coats & Jackets', 'Watches', 'Wallets & Money Clips', 'Underwear', 'Charms & Pendants', 'Candy & Chocolate', 'Costumes', 'Shorts', 'Baby One-Pieces', 'Backpacks', 'Shirts & Tops', 'Pet Supplies', 'Pants', 'Shoes', 'Dresses', 'Skirts', 'Earrings'}\n"
     ]
    }
   ],
   "source": [
    "# print length\n",
    "print(\"YELP length:\",len(yelp_texts))\n",
    "print(\"MAVE length:\",len(mave_texts))\n",
    "\n",
    "# print labels\n",
    "yelp_set = set()\n",
    "for label, _ in yelp_texts:\n",
    "    yelp_set.add(label)\n",
    "mave_set = set()\n",
    "for label, _ in mave_texts:\n",
    "    mave_set.add(label)\n",
    "print(\"YELP labels:\",yelp_set)\n",
    "print(\"MAVE labels:\",mave_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp train: 70238 test: 30103\n",
      "mave train: 70000 test: 30000\n"
     ]
    }
   ],
   "source": [
    "# create splits with fixed seed\n",
    "import random\n",
    "\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "# yelp\n",
    "yelp_length = len(yelp_texts)\n",
    "yelp_train_length = int(yelp_length * TRAIN_SPLIT)\n",
    "yelp_train_indices = random.sample(range(yelp_length), yelp_train_length)\n",
    "yelp_test_indices = [i for i in range(yelp_length) if i not in yelp_train_indices]\n",
    "\n",
    "# mave\n",
    "mave_length = len(mave_texts)\n",
    "mave_train_length = int(mave_length * TRAIN_SPLIT)\n",
    "mave_train_indices = random.sample(range(mave_length), mave_train_length)\n",
    "mave_test_indices = [i for i in range(mave_length) if i not in mave_train_indices]\n",
    "\n",
    "print(\"yelp train:\", len(yelp_train_indices), \"test:\", len(yelp_test_indices))\n",
    "print(\"mave train:\", len(mave_train_indices), \"test:\", len(mave_test_indices))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Binary Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# train\n",
    "with open(PATH_TO_BINARY_RESULTS + '_train.txt', 'w', encoding=\"utf8\") as f:\n",
    "    # write all except the last line\n",
    "    for i in yelp_train_indices:\n",
    "        f.write('service\\t' + yelp_texts[i][1] + '\\n')\n",
    "    for i in mave_train_indices[:-1]:\n",
    "        f.write('product\\t' + mave_texts[i][1] + '\\n')\n",
    "    f.write('product\\t' + mave_texts[mave_train_indices[-1]][1])\n",
    "\n",
    "# test\n",
    "with open(PATH_TO_BINARY_RESULTS + '_test.txt', 'w', encoding=\"utf8\") as f:\n",
    "    # write all except the last line\n",
    "    for i in yelp_test_indices:\n",
    "        f.write('service\\t' + yelp_texts[i][1] + '\\n')\n",
    "    for i in mave_test_indices[:-1]:\n",
    "        f.write('product\\t' + mave_texts[i][1] + '\\n')\n",
    "    f.write('product\\t' + mave_texts[mave_test_indices[-1]][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Multiclass Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# train\n",
    "with open(PATH_TO_RESULTS + '_train.txt', 'w', encoding=\"utf8\") as f:\n",
    "    # write all except the last line\n",
    "    for i in yelp_train_indices:\n",
    "        f.write(yelp_texts[i][0] + '\\t' + yelp_texts[i][1] + '\\n')\n",
    "    for i in mave_train_indices[:-1]:\n",
    "        f.write(mave_texts[i][0] + '\\t' + mave_texts[i][1] + '\\n')\n",
    "    f.write(mave_texts[mave_train_indices[-1]][0] + '\\t' + mave_texts[mave_train_indices[-1]][1])\n",
    "\n",
    "# test\n",
    "with open(PATH_TO_RESULTS + '_test.txt', 'w', encoding=\"utf8\") as f:\n",
    "    # write all except the last line\n",
    "    for i in yelp_test_indices:\n",
    "        f.write(yelp_texts[i][0] + '\\t' + yelp_texts[i][1] + '\\n')\n",
    "    for i in mave_test_indices[:-1]:\n",
    "        f.write(mave_texts[i][0] + '\\t' + mave_texts[i][1] + '\\n')\n",
    "    f.write(mave_texts[mave_test_indices[-1]][0] + '\\t' + mave_texts[mave_test_indices[-1]][1])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
